import unittest
from src.Lexer import *


class LexerTest(unittest.TestCase):
    def test_string(self):
        lexer = Lexer("  aaa  bb c dd  123     1a2a3b  $a  a$a 1$   ")
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "aaa"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "bb"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "c"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "dd"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "123"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "1a2a3b"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "$a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "a$a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "1$"))
        self.assertEqual(lexer.get_next_token(), Token(Type.EOF, None))

    def test_one_quote(self):
        lexer = Lexer("'aaa' b'b' 123 1a'2a3'b  ' '  '$'a ")
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "aaa"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "b"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "b"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "123"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "1a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "2a3"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "b"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "$"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.EOF, None))

    def test_two_quotes(self):
        lexer = Lexer('"aaa" bb "12"3 " ""1a"2ab"b "$a" ')
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "aaa"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "bb"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "12"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "3"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "1a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "2ab"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "b"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "$a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.EOF, None))

    def test_assignment(self):
        lexer = Lexer('a=aa"aa=\'=a b==b 123  $=a =')
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ASSIGNMENT, '='))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "aa"))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "aa"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ASSIGNMENT, '='))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ASSIGNMENT, '='))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "b"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ASSIGNMENT, '='))
        self.assertEqual(lexer.get_next_token(), Token(Type.ASSIGNMENT, '='))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "b"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "123"))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "$"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ASSIGNMENT, '='))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ASSIGNMENT, '='))
        self.assertEqual(lexer.get_next_token(), Token(Type.EOF, None))

    def test_pipe(self):
        lexer = Lexer("a=|aa \' |  || |\"| ")
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "a"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ASSIGNMENT, '='))
        self.assertEqual(lexer.get_next_token(), Token(Type.PIPE, '|'))
        self.assertEqual(lexer.get_next_token(), Token(Type.STRING, "aa"))
        self.assertEqual(lexer.get_next_token(), Token(Type.ONE_QUOTE, "'"))
        self.assertEqual(lexer.get_next_token(), Token(Type.PIPE, '|'))
        self.assertEqual(lexer.get_next_token(), Token(Type.PIPE, '|'))
        self.assertEqual(lexer.get_next_token(), Token(Type.PIPE, '|'))
        self.assertEqual(lexer.get_next_token(), Token(Type.PIPE, '|'))
        self.assertEqual(lexer.get_next_token(), Token(Type.TWO_QUOTES, '"'))
        self.assertEqual(lexer.get_next_token(), Token(Type.PIPE, '|'))
        self.assertEqual(lexer.get_next_token(), Token(Type.EOF, None))